{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOHDig/XYFn/5rLVPhs1Y5r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Get CelebA face images"],"metadata":{"id":"pdEFpyl1zujH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bpGxnHGbzPXv"},"outputs":[],"source":["!pip install -q kaggle"]},{"cell_type":"code","source":["from google.colab import files\n","\n","files.upload()"],"metadata":{"id":"vwyktxUIz-NM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","!kaggle datasets download -d jessicali9530/celeba-dataset -p /content/celeba/ --unzip"],"metadata":{"id":"xVxhXGa00E6H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import"],"metadata":{"id":"F-QQPFRF5KQX"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as T\n","import torchvision.utils as vutils\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from IPython.display import HTML\n","\n","manual_seed = 999\n","torch.manual_seed(manual_seed)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"1MS4KlDL27vU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"B5UQwsws5y6X"}},{"cell_type":"code","source":["# means and stds taken from the original DCGAN paper\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)"],"metadata":{"id":"jjfgFU4_51jH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1) Encoder"],"metadata":{"id":"Pxmd4MWR6FDi"}},{"cell_type":"code","source":["# structure based on the original VAEGAN and DCGAN paper\n","class Encoder(nn.Module):\n","  def __init__(self, z_dim=128):\n","    super(Encoder, self).__init__()\n","    self.conv1 = nn.Sequential(\n","        nn.Conv2d(3, 64, kernel_size=5, stride=2, padding=2, bias=False),\n","        nn.BatchNorm2d(64),\n","        nn.LeakyReLU(0.2, inplace=True)\n","    )\n","    self.conv2 = nn.Sequential(\n","        nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2, bias=False),\n","        nn.BatchNorm2d(128),\n","        nn.LeakyReLU(0.2, inplace=True)\n","    )\n","    self.conv3 = nn.Sequential(\n","        nn.Conv2d(128, 256, kernel_size=5, stride=2, padding=2, bias=False),\n","        nn.BatchNorm2d(256),\n","        nn.LeakyReLU(0.2, inplace=True)\n","    )\n","    self.fc = nn.Sequential(\n","        nn.Linear(256 * 8 * 8, 2048, bias=False),\n","        nn.BatchNorm1d(2048),\n","        nn.LeakyReLU(0.2, inplace=True)\n","    )\n","    self.mu = nn.Linear(2048, z_dim)\n","    self.log_var = nn.Linear(2048, z_dim)\n","\n","  def forward(self, x):\n","    x = self.conv1(x)\n","    x = self.conv2(x)\n","    x = self.conv3(x)\n","    x = self.fc(x.view(len(x), -1))\n","    mu = self.mu(x)\n","    log_var = self.log_var(x)\n","    return mu, log_var"],"metadata":{"id":"_GaOhj9R6DCo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2) Decoder"],"metadata":{"id":"Ozrwm9GACxUN"}},{"cell_type":"code","source":["# structure based on the original VAEGAN and DCGAN paper\n","class Decoder(nn.Module):\n","  def __init__(self, z_dim=128):\n","    super(Decoder, self).__init__()\n","    self.fc = nn.Sequential(\n","        nn.Linear(z_dim, 256 * 8 * 8, bias=False),\n","        nn.BatchNorm1d(256 * 8 * 8),\n","        nn.ReLU(True)\n","    )\n","    self.convt1 = nn.Sequential(\n","        nn.ConvTranspose2d(256, 256, kernel_size=5, stride=2, padding=2, output_padding=1, bias=False),\n","        nn.BatchNorm2d(256),\n","        nn.ReLU(True)\n","    )\n","    self.convt2 = nn.Sequential(\n","        nn.ConvTranspose2d(256, 128, kernel_size=5, stride=2, padding=2, output_padding=1, bias=False),\n","        nn.BatchNorm2d(128),\n","        nn.ReLU(True)\n","    )\n","    self.convt3 = nn.Sequential(\n","        nn.ConvTranspose2d(128, 32, kernel_size=5, stride=2, padding=2, output_padding=1, bias=False),\n","        nn.BatchNorm2d(32),\n","        nn.ReLU(True)\n","    )\n","    self.convt4 = nn.Sequential(\n","        nn.ConvTranspose2d(32, 3, kernel_size=5, stride=1, padding=2, bias=False),\n","        nn.Tanh()\n","    )\n","\n","  def forward(self, z):\n","    z = self.fc(z)\n","    z = self.convt1(z.view(-1, 256, 8, 8))\n","    z = self.convt2(z)\n","    z = self.convt3(z)\n","    return self.convt4(z)"],"metadata":{"id":"MUXufl47Cyoi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3) Discriminator"],"metadata":{"id":"1HfrxetlHEdf"}},{"cell_type":"code","source":["# structure based on the original VAEGAN and DCGAN paper\n","class Discriminator(nn.Module):\n","  def __init__(self):\n","    super(Discriminator, self).__init__()\n","    self.conv1 = nn.Sequential(\n","        nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2),\n","        nn.LeakyReLU(0.2, inplace=True)\n","    )\n","    self.conv2 = nn.Sequential(\n","        nn.Conv2d(32, 128, kernel_size=5, stride=2, padding=2),\n","        nn.BatchNorm2d(128),\n","        nn.LeakyReLU(0.2, inplace=True)\n","    )\n","    self.conv3 = nn.Sequential(\n","        nn.Conv2d(128, 256, kernel_size=5, stride=2, padding=2),\n","        nn.BatchNorm2d(256),\n","        nn.LeakyReLU(0.2, inplace=True)\n","    )\n","    self.conv4 = nn.Sequential(\n","        nn.Conv2d(256, 256, kernel_size=5, stride=2, padding=2),\n","        nn.BatchNorm2d(256),\n","        nn.LeakyReLU(0.2, inplace=True)\n","    )\n","    self.fc1 = nn.Sequential(\n","        nn.Linear(256 * 8 * 8, 512, bias=False),\n","        nn.BatchNorm1d(512),\n","        nn.LeakyReLU(0.2, inplace=True)\n","    )\n","    self.fc2 = nn.Sequential(\n","        nn.Linear(512, 1),\n","        nn.Sigmoid()\n","    )\n","\n","  def forward(self, x_original, x_recon, x_sampled):\n","    x = torch.cat((x_original, x_recon, x_sampled))\n","    x = self.conv1(x)\n","    x = self.conv2(x)\n","    x = self.conv3(x)\n","    x = self.conv4(x)\n","    x = self.fc1(x.view(len(x), -1))\n","    return self.fc2(x)"],"metadata":{"id":"XVES-PScHGU2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4) VAEGAN"],"metadata":{"id":"Jk9SDO7jML9H"}},{"cell_type":"code","source":["class VAEGAN(nn.Module):\n","  def __init__(self, z_dim=128):\n","    super(VAEGAN, self).__init__()\n","    self.z_dim = z_dim\n","    self.encoder = Encoder(z_dim)\n","    self.decoder = Decoder(z_dim)\n","    self.discriminator = Discriminator()\n","\n","    self.encoder.apply(weights_init)\n","    self.decoder.apply(weights_init)\n","    self.discriminator.apply(weights_init)\n","\n","  def forward(self, x):\n","    x_original = x.clone().detach()\n","\n","    mu, log_var = self.encoder(x)\n","    batch_size = len(mu)\n","    std = torch.exp(log_var * 0.5)\n","    epsilon = torch.normal(mean=torch.zeros(batch_size, self.z_dim), std=torch.ones(batch_size, self.z_dim)).to(device)\n","    z = epsilon * std + mu\n","    x_recon = self.decoder(z)\n","\n","    z_sampled = torch.normal(mean=torch.zeros(batch_size, self.z_dim), std=torch.ones(batch_size, self.z_dim)).to(device)\n","    x_sampled = self.decoder(z_sampled)\n","\n","    return mu, log_var, self.discriminator(x_original, x_recon, x_sampled)"],"metadata":{"id":"BmNL13XLIp6G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"C39va8TWTQ1Z"}},{"cell_type":"markdown","source":["## Hyperparameters"],"metadata":{"id":"ayv1-HnRWTid"}},{"cell_type":"code","source":["batch_size = 64\n","z_dim = 128\n","lr = 3e-4\n","gamma = 1 # to balance style error(GAN loss) and content error(reconstruction loss)\n","num_epochs = 5"],"metadata":{"id":"Pfh6ecQUWWdL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dataloader"],"metadata":{"id":"SJpyJcNK5ORp"}},{"cell_type":"code","source":["dataset = torchvision.datasets.ImageFolder(root=\"/content/celeba/img_align_celeba\",\n","                                           transform=T.Compose([\n","                                               T.Resize(64),\n","                                               T.CenterCrop(64),\n","                                               T.ToTensor(),\n","                                               T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","                                           ]))\n","dataloader = torch.utils.data.DataLoader(dataset, \n","                                         batch_size=batch_size,\n","                                         shuffle=True, \n","                                         num_workers=2)"],"metadata":{"id":"HH4QVA_j388o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Main"],"metadata":{"id":"Zhjeww7vZRnN"}},{"cell_type":"code","source":["real_batch = next(iter(dataloader))\n","vaegan = VAEGAN(z_dim).to(device)\n","criterion_BCE = nn.BCELoss()\n","criterion_MSE = nn.MSELoss()\n","optim_enc = optim.RMSprop(vaegan.encoder.parameters(), lr=lr)\n","optim_dec = optim.RMSprop(vaegan.decoder.parameters(), lr=lr)\n","optim_dis = optim.RMSprop(vaegan.discriminator.parameters(), lr=lr)\n","\n","fixed_z = torch.randn(64, z_dim, device=device)\n","img_list = []\n","losses_enc = []\n","losses_dec = []\n","losses_dis = []\n","iters = 0\n","\n","for epoch in range(num_epochs):\n","  for i, (data, _) in enumerate(dataloader):\n","    data = data.to(device)\n","    mu, log_var, dis = vaegan(data)\n","\n","    # unpack the output of discriminator, input order was \"x_original -> x_recon -> x_sampled\"\n","    dis_x_original = dis[:batch_size, :]\n","    dis_x_recon = dis[batch_size:2*batch_size, :]\n","    dis_x_sampled = dis[2*batch_size:, :]\n","    real_label = torch.ones((batch_size, 1), requires_grad=False).to(device)\n","    fake_label = torch.zeros((batch_size, 1), requires_grad=False).to(device)\n","    bce_dis_x_original = criterion_BCE(dis_x_original, real_label)\n","    bce_dis_x_recon = criterion_BCE(dis_x_recon, fake_label)\n","    bce_dis_x_sampled = criterion_BCE(dis_x_sampled, fake_label)\n","\n","    loss_prior = torch.mean(0.5 * torch.sum(torch.pow(mu,2) + torch.exp(log_var) - log_var - 1, dim=1))\n","    loss_recon = criterion_MSE(dis_x_original, dis_x_recon)\n","    loss_gan = bce_dis_x_original + bce_dis_x_recon + bce_dis_x_sampled\n","\n","    loss_enc = loss_prior + loss_recon\n","    loss_dec = gamma * loss_recon - loss_gan\n","    loss_dis = loss_gan\n","\n","    losses_enc.append(loss_enc.item())\n","    losses_dec.append(loss_dec.item())\n","    losses_dis.append(loss_dis.item())\n","\n","    optim_enc.zero_grad()\n","    loss_enc.backward(inputs=list(vaegan.encoder.parameters()), retain_graph=True)\n","    optim_enc.step()\n","\n","    optim_dec.zero_grad()\n","    loss_dec.backward(inputs=list(vaegan.decoder.parameters()),retain_graph=True)\n","    optim_dec.step()\n","\n","    optim_dis.zero_grad()\n","    loss_dis.backward(inputs=list(vaegan.discriminator.parameters()))\n","    optim_dis.step()\n","\n","    if iters % 500 == 0:\n","      with torch.no_grad():\n","        fake_img = vaegan.decoder(fixed_z).detach().cpu()\n","      img_list.append(vutils.make_grid(fake_img, padding=2, normalize=True))\n","\n","    iters += 1"],"metadata":{"id":"2C1RM3WsTTNO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# source from https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n","plt.figure(figsize=(10,5))\n","plt.plot(losses_enc, label=\"Encoder\")\n","plt.plot(losses_dec, label=\"Decoder\")\n","plt.plot(losses_dis, label=\"Discriminator\")\n","plt.xlabel(\"Iterations\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"o4xdsfNGXzyd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# source from https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n","fig = plt.figure(figsize=(8,8))\n","plt.axis(\"off\")\n","ims = [[plt.imshow(np.transpose(i, (1,2,0)), animated=True)] for i in img_list]\n","ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n","\n","HTML(ani.to_jshtml())"],"metadata":{"id":"aNO5gQzvZ402"},"execution_count":null,"outputs":[]}]}